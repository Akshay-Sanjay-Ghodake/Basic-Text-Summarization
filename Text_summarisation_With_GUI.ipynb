{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "try:\r\n",
    "    from tkinter import *\r\n",
    "except ImportError:\r\n",
    "    from Tkinter import *\r\n",
    "import time\r\n",
    "from tkinter import filedialog\r\n",
    "from tkinter import messagebox\r\n",
    "import io \r\n",
    "from nltk.corpus import stopwords \r\n",
    "from nltk.tokenize import word_tokenize \r\n",
    "import bs4 as bs  \r\n",
    "import urllib.request  \r\n",
    "import re  \r\n",
    "import nltk\r\n",
    "import heapq "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "gui = Tk()\r\n",
    "gui.title(\"Text Summerization\")\r\n",
    "width = 600\r\n",
    "height = 262\r\n",
    "screen_width = gui.winfo_screenwidth()\r\n",
    "screen_height = gui.winfo_screenheight()\r\n",
    "x = (screen_width/2) - (width/2)\r\n",
    "y = (screen_height/2) - (height/2)\r\n",
    "gui.geometry(\"%dx%d+%d+%d\" % (width, height, x, y))\r\n",
    "path = StringVar()\r\n",
    "Top = Frame(gui, width=width)\r\n",
    "Top.pack(side=TOP)\r\n",
    "Form = Frame(gui, width=width)\r\n",
    "Form.pack(side=TOP)\r\n",
    "Bot = Frame(gui, width=width)\r\n",
    "Bot.pack(side=BOTTOM)\r\n",
    "\r\n",
    "lbl_title = Label(Top, width=width, font=('sans serif', 12, 'bold'), text=\" Summarizer\", bd=1, relief=SOLID)\r\n",
    "lbl_title.pack(fill=X)\r\n",
    "lbl_instructions = Label(Bot, width=width, font=('sans serif', 12, 'bold'), text=\"Result will be on output file.\", bd=1, relief=SOLID)\r\n",
    "lbl_instructions.pack(fill=X)\r\n",
    "\r\n",
    "def browsefunc():\r\n",
    "    filename = filedialog.askopenfilename()\r\n",
    "    pathlabel.config(text=filename)\r\n",
    "    file1 = open(filename) \r\n",
    "    line = file1.read() \r\n",
    "    parsed_article = bs.BeautifulSoup(line,'lxml') \r\n",
    "    paragraphs = parsed_article.find_all('p') \r\n",
    "    article_text = \"\"\r\n",
    "    for p in paragraphs:  \r\n",
    "        article_text += p.text\r\n",
    "    article_text = re.sub(r'\\[[0-9]*\\]', ' ', article_text)  \r\n",
    "    article_text = re.sub(r'\\s+', ' ', article_text)\r\n",
    "    formatted_article_text = re.sub('[^a-zA-Z]', ' ', article_text )  \r\n",
    "    formatted_article_text = re.sub(r'\\s+', ' ', formatted_article_text) \r\n",
    "    sentence_list = nltk.sent_tokenize(article_text)\r\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\r\n",
    "    word_frequencies = {}  \r\n",
    "    for word in nltk.word_tokenize(formatted_article_text):  \r\n",
    "        if word not in stopwords:\r\n",
    "            if word not in word_frequencies.keys():\r\n",
    "                word_frequencies[word] = 1\r\n",
    "            else:\r\n",
    "                word_frequencies[word] += 1\r\n",
    "    maximum_frequncy = max(word_frequencies.values())\r\n",
    "    for word in word_frequencies.keys(): \r\n",
    "        word_frequencies[word] = (word_frequencies[word]/maximum_frequncy)\r\n",
    "    sentence_scores = {}  \r\n",
    "    for sent in sentence_list:  \r\n",
    "        for word in nltk.word_tokenize(sent.lower()):\r\n",
    "            if word in word_frequencies.keys():\r\n",
    "                if len(sent.split(' ')) < 30:\r\n",
    "                    if sent not in sentence_scores.keys():\r\n",
    "                        sentence_scores[sent] = word_frequencies[word]\r\n",
    "                    else:\r\n",
    "                        sentence_scores[sent] += word_frequencies[word]\r\n",
    "                    \r\n",
    "    summary_sentences = heapq.nlargest(5, sentence_scores, key=sentence_scores.get)\r\n",
    "    s1=[]\r\n",
    "    a=len(sentence_list)\r\n",
    "    for i in range (0, a):\r\n",
    "        for j in range (0, len(summary_sentences)):\r\n",
    "            if sentence_list[i]==summary_sentences[j]:\r\n",
    "                s1.append(sentence_list[i])\r\n",
    "                j=j+1\r\n",
    "        i=i+1\r\n",
    "    s1.append(sentence_list[a-1])\r\n",
    "    summary = ''.join(s1)  \r\n",
    "    for r in summary: \r\n",
    "        appendFile = open('C:\\\\Akshay\\\\Study\\\\Projects\\\\Text\\\\filteredtext.txt  ','a')\r\n",
    "        appendFile.write(\"\"+r) \r\n",
    "        appendFile.close()\r\n",
    "\r\n",
    "    \r\n",
    "def clicked():\r\n",
    "    messagebox.showinfo('Summerization ', 'Text Summarization Successfully.....')\r\n",
    "        \r\n",
    "pathlabel = Label(Form, text=\"Path----\")\r\n",
    "pathlabel.grid(row=1, column=1)\r\n",
    "\r\n",
    "btn_generate = Button(Form, text=\"Summarize\", width=20,command=clicked)\r\n",
    "btn_generate1 = Button(Form, text=\"Browser\", width=20, command=browsefunc)\r\n",
    "btn_generate.grid(row=4, column=1, columnspan=2)\r\n",
    "\r\n",
    "pathlabel.grid(row=1, column=3)\r\n",
    "btn_generate1.grid(row=4, column=3,columnspan=4)\r\n",
    "\r\n",
    "gui.mainloop()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}